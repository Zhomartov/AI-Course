# Нейронные сети для начинающих: Перцептрон

_Перцептро́н_ (или персептрон (англ. perceptron от лат. **_perceptio_** — восприятие; нем. **_Perzeptron_**)) — математическая или компьютерная модель восприятия информации мозгом (кибернетическая модель мозга), предложенная _Фрэнком Розенблаттом_ в 1957 году и впервые воплощённая в виде электронной машины «Марк-1» в 1960 году. Перцептрон стал одной из первых моделей нейросетей, а «Марк-1» — первым в мире нейрокомпьютером.

| [!Frank](./images/Фрэнк_Розенблатт.png) | [!Mark](./images/MARK%20_1%20.jpg) |
| :-------------------------------------: | :--------------------------------: |
|            Фрэнк Розенблатт             |         «Марк-1» (MARK 1)          |

## Перцептрон состоит из трёх типов элементов:

1. Поступающие от датчиков сигналы
2. Ассоциативным элементам
3. Реагирующим элементам.

Таким образом, перцептроны позволяют создать набор «ассоциаций» между входными стимулами и необходимой реакцией на выходе. В биологическом плане это соответствует преобразованию, например, зрительной информации в физиологический ответ от двигательных нейронов. Согласно современной терминологии, перцептроны могут быть классифицированы как искусственные нейронные сети:

1.  с одним скрытым слоем;
2.  с пороговой передаточной функцией;
3.  с прямым распространением сигнала.

    |          [!Schema](./images/Перцентрон.jpg)           |
    | :---------------------------------------------------: |
    | Схема однослойного персептрона для распознавание цифр |

## Описание элементарного перцептрона

Элементарный перцептрон состоит из трёх основных типов элементов: S-элементов, A-элементов и одного R-элемента.

1. **S-элементы** — это сенсоры или рецепторы, выполняющие роль входного слоя. В физическом смысле их можно представить как светочувствительные клетки сетчатки глаза или фоторезисторы камеры. Каждый такой элемент может быть в одном из двух состояний — "активен" или "неактивен". Если он активен, то передаёт единичный сигнал на следующий слой — к ассоциативным элементам.
2. **A-элементы**, или ассоциативные элементы, принимают сигналы от группы связанных с ними S-элементов. A-элемент активируется, когда количество сигналов от связанных S-элементов превышает определённый порог θ. Например, если S-элементы, которые образуют форму буквы "Д", одновременно передают активные сигналы, A-элемент срабатывает, фиксируя "наличие" этой формы в сенсорном поле.
3. **R-элемент** выполняет роль сумматора. Он принимает сигналы от активированных A-элементов, где каждый сигнал умножается на определённый вес $\( w_i \)$, характеризующий значимость связи между конкретным A-элементом и R-элементом. R-элемент вычисляет взвешенную сумму всех поступивших сигналов и выдает результат: если сумма превышает порог 0, на выходе будет "1", иначе "−1". Это можно выразить математически: <br/>
   $\ f(x) = \text{sign} \left( \sum*{i=1}^{n} w*{i} x\_{i} - \theta \right)\$

## Процесс обучения

Обучение перцептрона заключается в корректировке весов $\( w_i \)$ между A- и R-элементами. Веса связей между S- и A-элементами (которые могут принимать значения −1, 0 или +1) и пороги активации для A-элементов задаются случайным образом при инициализации и остаются неизменными на протяжении всего обучения.

## Режим распознавания

После завершения обучения перцептрон готов к распознаванию новых данных. Когда на вход поступает ранее неизвестный объект, активируются соответствующие A-элементы, передавая сигналы на R-элемент, где происходит суммирование с учетом весов $\( w_i \)$. Если итоговая сумма положительна, перцептрон относит объект к одному классу, если отрицательна — к другому.

## Алогиртм в Python будет выгледить так [! terminal](./images/terminal.png) :

```
python
def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):

    weights = [0,0,0] # Initialize weights (almost randomly :)

    for i in range(num_iterations):
        pos = random.choice(positive_examples)
        neg = random.choice(negative_examples)

        z = np.dot(pos, weights) # compute perceptron output
        if z < 0: # positive example classified as negative
            weights = weights + eta*weights.shape

        z  = np.dot(neg, weights)
        if z >= 0: # negative example classified as positive
            weights = weights - eta*weights.shape

    return weights
```
